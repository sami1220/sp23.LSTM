{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.7.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit ('sub': conda)"
    },
    "interpreter": {
      "hash": "15fd5775daec78a3d2b557d938fb15a01a1c62fbdbfe50f040346c1054e408d2"
    },
    "colab": {
      "name": "sp23.LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozvmHUncPzB3"
      },
      "source": [
        "# Sprint23 LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG_8EsPMPzB7"
      },
      "source": [
        "## 【問題1】各種手法の実行\n",
        "\n",
        "Kerasには4種類のReccurentレイヤーが用意されています。\n",
        "\n",
        "SimpleRNN以外はゲート付きリカレントニューラルネットワークです。\n",
        "\n",
        "\n",
        "**SimpleRNN**\n",
        "\n",
        "**GRU**\n",
        "\n",
        "**LSTM**\n",
        "\n",
        "**ConvLSTM2D**\n",
        "\n",
        "これらを実行してください。\n",
        "この中でSimpleRNN、GRU、LSTMは同様のタスクに用いることができるため、精度の比較も行なってください。\n",
        "\n",
        "\n",
        "Keras公式のサンプルコードを利用してください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5YkTNe6bP6VD",
        "outputId": "c97f0638-7041-4db5-f915-62a1fe5f1a9b"
      },
      "source": [
        "# pip list\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbAe3ap3QckY"
      },
      "source": [
        "LSTMのサンプルコードを動かしてみる\n",
        "\n",
        "[https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/imdb_lstm.py](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5UF9NmYPzB8",
        "outputId": "790df26d-1cb6-4e1b-9741-8be310d89ba9"
      },
      "source": [
        "'''-----翻訳-----\n",
        "IMDBの感情分類タスクでLSTMモデルを学習します。\n",
        "データセットが小さすぎるため、TF-IDF + LogRegのような単純で高速な手法と比較して、LSTMにはメリットがありません。\n",
        "TF-IDF + LogRegのようなシンプルで高速な手法と比較して、LSTMには利点がありません。\n",
        "# 注意点\n",
        "- RNNは厄介です。バッチサイズの選択が重要。\n",
        "損失とオプティマイザの選択が重要など。\n",
        "収束しない設定もある。\n",
        "- LSTMの学習中の損失減少パターンは、CNNやMLPなどとは\n",
        "CNNやMLPなどで見られるものとはかなり異なる可能性があります。\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "\n",
        "max_features = 20000\n",
        "# この語数以降のテキストをカット（max_featuresの上位の最もよく使われる語の中から\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "# 学習に使うデータの用意&確認\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('Build model...')\n",
        "\n",
        "# モデルを定義\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 異なるオプティマイザーとオプティマイザーの設定を使用してみてください。\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=5,#epochを15から5へ変更\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "Build model...\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Train...\n",
            "Epoch 1/5\n",
            "782/782 [==============================] - 479s 608ms/step - loss: 0.4463 - accuracy: 0.7876 - val_loss: 0.3746 - val_accuracy: 0.8353\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 469s 600ms/step - loss: 0.2574 - accuracy: 0.8966 - val_loss: 0.4137 - val_accuracy: 0.8282\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 468s 599ms/step - loss: 0.1668 - accuracy: 0.9380 - val_loss: 0.4727 - val_accuracy: 0.8272\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 463s 592ms/step - loss: 0.1139 - accuracy: 0.9592 - val_loss: 0.5306 - val_accuracy: 0.8196\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 467s 597ms/step - loss: 0.0824 - accuracy: 0.9714 - val_loss: 0.5934 - val_accuracy: 0.8196\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.5934 - accuracy: 0.8196\n",
            "Test score: 0.593350887298584\n",
            "Test accuracy: 0.8196399807929993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5NllMXUQ3jV"
      },
      "source": [
        "ConvLSTM2Dのサンプルコードを動かしてみる\n",
        "\n",
        "[https://github.com/awslabs/keras-apache-mxnet/blob/master/examples/conv_lstm.py](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkao1MEBcBbE",
        "outputId": "0177ac23-160c-4e47-cff6-68973f4917a3"
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 71 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 81 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 107 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=75a99c9988084a6512900a9ca04f6a8a24822c1f6a358be3726f23dc9a0e0586\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQEh7b-PzB9"
      },
      "source": [
        "\"\"\" このスクリプトは、畳み込みLSTMネットワークの使用方法を示しています。\n",
        "このネットワークは、動く四角形を含む人工的に生成されたムービーの次のフレームを予測するために使用されます。\n",
        "次のフレームを予測します。\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv3D\n",
        "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "# from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "from tf.keras import backend as K\n",
        "\n",
        "if K.backend() == 'mxnet':\n",
        "    raise NotImplementedError(\"MXNet Backend: ConvLSTM2D Layer is not supported yet.\")\n",
        "\n",
        "# の形をしたムービーを入力とするレイヤーを作成します。\n",
        "# (n_frames, width, height, channels)のムービーを入力とし、\n",
        "# 同じ形の # ムービーを返すレイヤーを作ります。\n",
        "\n",
        "seq = Sequential()\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   input_shape=(None, 40, 40, 1),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(ConvLSTM2D(filters=40, kernel_size=(3, 3),\n",
        "                   padding='same', return_sequences=True))\n",
        "seq.add(BatchNormalization())\n",
        "\n",
        "seq.add(Conv3D(filters=1, kernel_size=(3, 3, 3),\n",
        "               activation='sigmoid',\n",
        "               padding='same', data_format='channels_last'))\n",
        "seq.compile(loss='binary_crossentropy', optimizer='adadelta')\n",
        "\n",
        "# 人工的なデータ生成。\n",
        "# 内部に3〜7個の動く四角形がある動画を生成する。\n",
        "# 升目の形状は1x1または2x2ピクセル。\n",
        "# ピクセルの形をしており、時間の経過とともに直線的に動きます。\n",
        "# ここでは、便宜上、幅と高さが大きいムービー（80x80）を作成し、最後に40x40のウィンドウを選択します。\n",
        "# を作成し、最後に40x40のウィンドウを選択する。\n",
        "\n",
        "def generate_movies(n_samples=1200, n_frames=15):\n",
        "    row = 80\n",
        "    col = 80\n",
        "    noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.float)\n",
        "    shifted_movies = np.zeros((n_samples, n_frames, row, col, 1),\n",
        "                              dtype=np.float)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        # 3～7マスの移動マスを追加\n",
        "        n = np.random.randint(3, 8)\n",
        "\n",
        "        for j in range(n):\n",
        "            # 初期位置\n",
        "            xstart = np.random.randint(20, 60)\n",
        "            ystart = np.random.randint(20, 60)\n",
        "            # 動きの方向\n",
        "            directionx = np.random.randint(0, 3) - 1\n",
        "            directiony = np.random.randint(0, 3) - 1\n",
        "\n",
        "            # サイズ\n",
        "            w = np.random.randint(2, 4)\n",
        "\n",
        "            for t in range(n_frames):\n",
        "                x_shift = xstart + directionx * t\n",
        "                y_shift = ystart + directiony * t\n",
        "                noisy_movies[i, t, x_shift - w: x_shift + w,\n",
        "                             y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "                # ノイズを加えることで、よりロバストにする。\n",
        "                # 考え方としては、推論中に\n",
        "                # 推論中にピクセルの値が正確に1ではない場合は\n",
        "                # ロバストになるようにネットワークを訓練し、それでもなお\n",
        "                # 正方形に属するピクセルとみなします。\n",
        "                if np.random.randint(0, 2):\n",
        "                    noise_f = (-1)**np.random.randint(0, 2)\n",
        "                    noisy_movies[i, t,\n",
        "                                 x_shift - w - 1: x_shift + w + 1,\n",
        "                                 y_shift - w - 1: y_shift + w + 1,\n",
        "                                 0] += noise_f * 0.1\n",
        "\n",
        "                # グラウンドトゥルースを1だけシフト\n",
        "                x_shift = xstart + directionx * (t + 1)\n",
        "                y_shift = ystart + directiony * (t + 1)\n",
        "                shifted_movies[i, t, x_shift - w: x_shift + w,\n",
        "                               y_shift - w: y_shift + w, 0] += 1\n",
        "\n",
        "    # 40x40 windowにカットする\n",
        "    noisy_movies = noisy_movies[::, ::, 20:60, 20:60, ::]\n",
        "    shifted_movies = shifted_movies[::, ::, 20:60, 20:60, ::]\n",
        "    noisy_movies[noisy_movies >= 1] = 1\n",
        "    shifted_movies[shifted_movies >= 1] = 1\n",
        "    return noisy_movies, shifted_movies\n",
        "\n",
        "# ネットワークの学習\n",
        "noisy_movies, shifted_movies = generate_movies(n_samples=1200)\n",
        "seq.fit(noisy_movies[:1000], shifted_movies[:1000], batch_size=10,\n",
        "        epochs=150, validation_split=0.05)#epochを300→150へ変更\n",
        "\n",
        "# 1つのムービーでネットワークをテスト\n",
        "# 最初の7つのポジションをネットワークに入力してから\n",
        "# 新しい位置を予測する\n",
        "which = 1004\n",
        "track = noisy_movies[which][:7, ::, ::, ::]\n",
        "\n",
        "for j in range(16):\n",
        "    new_pos = seq.predict(track[np.newaxis, ::, ::, ::, ::])\n",
        "    new = new_pos[::, -1, ::, ::, ::]\n",
        "    track = np.concatenate((track, new), axis=0)\n",
        "\n",
        "track2 = noisy_movies[which][::, ::, ::, ::]\n",
        "for i in range(15):\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    ax = fig.add_subplot(121)\n",
        "\n",
        "    if i >= 7:\n",
        "        ax.text(1, 3, 'Predictions !', fontsize=20, color='w')\n",
        "    else:\n",
        "        ax.text(1, 3, 'Initial trajectory', fontsize=20)\n",
        "\n",
        "    toplot = track[i, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    ax = fig.add_subplot(122)\n",
        "    plt.text(1, 3, 'Ground truth', fontsize=20)\n",
        "\n",
        "    toplot = track2[i, ::, ::, 0]\n",
        "    if i >= 2:\n",
        "        toplot = shifted_movies[which][i - 1, ::, ::, 0]\n",
        "\n",
        "    plt.imshow(toplot)\n",
        "    plt.savefig('%i_animate.png' % (i + 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSIec1eBVMWy"
      },
      "source": [
        "SimpleRNNを動かしてみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeHRGvAyVLI_"
      },
      "source": [
        "# ライブラリのimport \n",
        "# ライブラリのimport\n",
        "from keras.layers.recurrent import SimpleRNN\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "\n",
        "# keras.layers.SimpleRNN(units, activation='tanh', use_bias=True, \n",
        "#                        kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n",
        "#                        bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, \n",
        "#                        bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
        "#                        recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, \n",
        "#                        return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4KCm0SvmNbt",
        "outputId": "939c7b1d-ad91-4f58-949c-79648b121c60"
      },
      "source": [
        "#  imdbデータの読み込みと整形\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 確認\n",
        "x_train.shape, y_train.shape,x_test.shape, y_test.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 80), (25000,), (25000, 80), (25000,))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxPGnEeWmQXi",
        "outputId": "2f45b653-105e-44ee-c4c4-430e4b429cb2"
      },
      "source": [
        "# モデルの定義\n",
        "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTmk6_rPmyPA",
        "outputId": "a4a63af2-b3c9-4cb1-d18d-690bb3c02133"
      },
      "source": [
        "# コンパイルと学習\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=1,\n",
        "    validation_data=(x_test, y_test)\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 461s 586ms/step - loss: 0.4291 - accuracy: 0.7980 - val_loss: 0.3929 - val_accuracy: 0.8399\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e61db66d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGBLIlAYmTIC",
        "outputId": "a1017bb9-52a6-4708-e095-42d7ca6ef4a8"
      },
      "source": [
        "# 評価\n",
        "score, acc = model.evaluate(\n",
        "    x_test, \n",
        "    y_test,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 27s 34ms/step - loss: 0.3929 - accuracy: 0.8399\n",
            "Test score: 0.3928980529308319\n",
            "Test accuracy: 0.8398799896240234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLPvlW0_qfK7"
      },
      "source": [
        "GRUを動かしてみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1x8-37DqhgA",
        "outputId": "6be37415-4da9-4c6b-be3d-ea6d714c3ae9"
      },
      "source": [
        "from keras.layers.recurrent import GRU\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "\n",
        "# imdbデータの読み込みと整形\n",
        "max_features = 20000\n",
        "maxlen = 80\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# 確認\n",
        "x_train.shape, y_train.shape,x_test.shape, y_test.shape\n",
        "\n",
        "# モデルの定義\n",
        "# Embeddingに関して：https://kento1109.hatenablog.com/entry/2017/12/02/114515\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "# コンパイルと学習\n",
        "batch_size = 32\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=1,\n",
        "    validation_data=(x_test, y_test)\n",
        ")\n",
        "\n",
        "# 評価\n",
        "score, acc = model.evaluate(\n",
        "    x_test, \n",
        "    y_test,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 128)               98688     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,658,817\n",
            "Trainable params: 2,658,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "782/782 [==============================] - 532s 675ms/step - loss: 0.4388 - accuracy: 0.7888 - val_loss: 0.3647 - val_accuracy: 0.8424\n",
            "782/782 [==============================] - 26s 33ms/step - loss: 0.3647 - accuracy: 0.8424\n",
            "Test score: 0.3647356629371643\n",
            "Test accuracy: 0.8424000144004822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVtt3x2tq5zY"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgosGdWiWP65"
      },
      "source": [
        "## 【問題3】他のクラスの説明\n",
        "\n",
        "ドキュメントには他にも関連するクラスが記載されています。\n",
        "\n",
        "それらがどういうものなのかを説明してください。\n",
        "\n",
        "この中には実際に扱うことは少ないクラスも含まれています。\n",
        "\n",
        "\n",
        "RNN\n",
        "\n",
        "SimpleRNNCell\n",
        "\n",
        "GRUCell\n",
        "\n",
        "LSTMCell\n",
        "\n",
        "StackedRNNCells\n",
        "\n",
        "CuDNNGRU\n",
        "\n",
        "CuDNNLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89XSlgouWUuR"
      },
      "source": [
        "### 回答\n",
        "\n",
        "\n",
        "*   RNN　：再帰型ニューラルネットワーク（RNN）は、時系列や自然言語などのシーケンスデータのモデリングを強力に行うニューラルネットワークのクラスです。\n",
        "*   SimpleRNNCell　：　SimpleRNNは前の時間ステップが次の時間ステップにフィードされる連結されたRNN\n",
        "*   GRUCell　：　LSTMと同等の性能を持つが、LSTMより計算量が少なく高速な学習が可能（しかし表現能力はLSTMに劣るとの意見もあり）\n",
        "*   LSTMCell　：　RNNで不可能であった長期的特徴の学習を可能にしたcell　計算コストが大きい\n",
        "*   StackedRNNCells　：　RNNセルスタックの動作を単一セルのように見せるためのラッパーです。\n",
        "*   CuDNNGRU　：　CuDNNを使った高速GRUの実装です。\n",
        "*   CuDNNLSTM　：　CuDNNを用いた高速なLSTM実装です。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfn1YasFrFqv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}